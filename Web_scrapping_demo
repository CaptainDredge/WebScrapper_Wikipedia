from bs4 import BeautifulSoup
import requests
import re
import operator
import json
from tabulate import tabulate
import sys
from stop_words import get_stop_words


def getWordList(url):

    response=requests.get(url)
    soup=BeautifulSoup(response.content, 'lxml')
    word_list=[]

    for text in soup.findAll('p'):
        if(text.get_text()==None):
            continue
        else:
            content=text.get_text()
            words=content.lower().split()

            for word in words:
                cleaned_word = clean_word(word)
            #if there is still something there
                if len(cleaned_word) > 0:
                #add it to our word list
                    word_list.append(cleaned_word)
    return word_list

def clean_word(word):
    cleaned_word=re.sub('[^A-z|a-z]+','',word)
    return cleaned_word

def createFrequencyTable(word_list):
    frequency_table={}
    for word in word_list:
        if word in frequency_table:
            frequency_table[word]+=1
        else:
            frequency_table[word]=1

    return frequency_table


def remove_stop_words(frequency_list):
    stop_words = get_stop_words('en')

    temp_list = []
    for key,value in frequency_list:
        if key not in stop_words:
            temp_list.append([key, value])

    return temp_list





wikipedia_api_link="https://en.wikipedia.org/w/api.php?format=json&action=query&list=search&srsearch="
wikipedia_link = "https://en.wikipedia.org/wiki/"

if (len(sys.argv)<2):
    print('Enter valid string')
    exit()

string_query=sys.argv[1]

if (len(sys.argv)>2):
    search_mode=True
else:
    search_mode=False


url=wikipedia_api_link+string_query

try:
    response=requests.get(url)
    response.raise_for_status()
    data=json.loads(response.content.decode('utf-8'))

    Wikipedia_page_tag=data['query']['search'][0]['title']

    url=wikipedia_link+Wikipedia_page_tag
    page_word_list=getWordList(url)

    page_word_count=createFrequencyTable(page_word_list)
    sorted_word_frequency_list=sorted(page_word_count.items(), key=operator.itemgetter(1), reverse=True)

    if (search_mode):
        sorted_word_frequency_list=remove_stop_words(sorted_word_frequency_list)

    total_words_sum=0
    for key, value in sorted_word_frequency_list:
        total_words_sum=total_words_sum+value

    if len(sorted_word_frequency_list)>20:
        sorted_word_frequency_list=sorted_word_frequency_list[:20]

    final_list=[]
    for key, value in sorted_word_frequency_list:
        percentage_value=float(value*100)/total_words_sum
        final_list.append([key, value, round(percentage_value,4)])

    print_headers =['word', 'Frequency','Frequency Percentage']
    print(tabulate(final_list, headers=print_headers, tablefmt='orgtbl'))

#throw an exception in case it breaks
except requests.exceptions.Timeout:
    print("The server didn't respond. Please, try again later.")
